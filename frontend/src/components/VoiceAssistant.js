// src/components/VoiceAssistant.js
import React, { useState } from "react";
import { MicrophoneIcon, StopCircleIcon } from "@heroicons/react/24/solid";

export default function VoiceAssistant() {
  const [recording, setRecording] = useState(false);
  const [message, setMessage] = useState("ðŸŽ™ï¸ Tap the mic to speak");
  const [mediaRecorder, setMediaRecorder] = useState(null);

  const startRecording = async () => {
    try {
      const stream = await navigator.mediaDevices.getUserMedia({ audio: true });

      const recorder = new MediaRecorder(stream);
      let chunks = [];

      recorder.ondataavailable = (event) => chunks.push(event.data);

      recorder.onstop = async () => {
        setRecording(false);
        setMessage("ðŸ§  Processing your voice...");

        const blob = new Blob(chunks, { type: "audio/webm" });
        const formData = new FormData();
        formData.append("file", blob, "voice.webm");

        try {
          // âœ… Step 1 â€” Send audio to /speech
          const speechRes = await fetch("http://localhost:9000/speech", {
            method: "POST",
            body: formData,
          });

          const speechData = await speechRes.json();
          const text = speechData.text?.trim() || "";

          if (!text) {
            setMessage("â— No speech detected. Try again.");
            return;
          }

          setMessage(`ðŸ—£ï¸ You said: "${text}"`);

          // âœ… Step 2 â€” Send text to /process
          const aiRes = await fetch("http://localhost:9000/process", {
            method: "POST",
            headers: { "Content-Type": "application/json" },
            body: JSON.stringify({ text }),
          });

          // âœ… âœ… READ AS TEXT â€” NOT JSON
          const reply = await aiRes.text();

          setMessage(`ðŸ¤– ${reply}`);

        } catch (err) {
          console.error(err);
          setMessage("âš ï¸ Could not reach AI service.");
        } finally {
          stream.getTracks().forEach((t) => t.stop());
        }
      };

      recorder.start();
      setRecording(true);
      setMediaRecorder(recorder);
      setMessage("ðŸŽ§ Listening... speak now");

      // âœ… Auto-stop after 4 seconds
      setTimeout(() => {
        if (recorder.state === "recording") recorder.stop();
      }, 4000);

    } catch (err) {
      console.error(err);
      setMessage("ðŸš« Microphone access blocked.");
    }
  };

  const stopRecording = () => {
    if (mediaRecorder && mediaRecorder.state === "recording") {
      mediaRecorder.stop();
    }
    setRecording(false);
    setMessage("âœ… Stopped recording");
  };

  return (
    <div className="p-6 bg-white dark:bg-gray-800 rounded-xl shadow text-center">
      <h2 className="text-xl font-bold mb-4">Voice Assistant</h2>

      <button
        onClick={recording ? stopRecording : startRecording}
        className={`w-24 h-24 rounded-full text-white flex items-center justify-center mx-auto mb-4 ${
          recording ? "bg-red-600" : "bg-indigo-600"
        }`}
      >
        {recording ? (
          <StopCircleIcon className="h-12 w-12" />
        ) : (
          <MicrophoneIcon className="h-12 w-12" />
        )}
      </button>

      <div className="p-4 bg-gray-100 dark:bg-gray-700 rounded-lg text-sm min-h-[140px]">
        {message}
      </div>
    </div>
  );
}
